<!DOCTYPE html>












  


<html class="theme-next muse use-motion" lang="zh-Hans">
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge"/>
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2"/>
<meta name="theme-color" content="#222"/>
























<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2"/>

<link rel="stylesheet" href="/css/main.css?v=7.1.0"/>


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=7.1.0">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=7.1.0">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=7.1.0">


  <link rel="mask-icon" href="/images/logo.svg?v=7.1.0" color="#222">







<script id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    version: '7.1.0',
    sidebar: {"position":"left","display":"post","offset":12,"onmobile":false,"dimmer":false},
    back2top: true,
    back2top_sidebar: false,
    fancybox: false,
    fastclick: false,
    lazyload: false,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>


  




  <meta name="description" content="一. 学习内容 前馈神经网络 Feedforward Neural Network 卷积神经网络 Convolutional Neural Network 激活函数 Activation Function  1. 前馈神经网络这里用depth只有1的灰度图来举例。 想要完成的任务是：在宽长为4x4的图片中识别是否有下图所示的“横折”。 图中，黄色圆点表示值为0的像素，深色圆点表示值为1的像素。 我">
<meta name="keywords" content="cnn,activation function">
<meta property="og:type" content="article">
<meta property="og:title" content="cs231n study note 2">
<meta property="og:url" content="http://godshen.github.io/2018/05/14/cs231n-study-note-2/index.html">
<meta property="og:site_name" content="沈中皓同学不好学">
<meta property="og:description" content="一. 学习内容 前馈神经网络 Feedforward Neural Network 卷积神经网络 Convolutional Neural Network 激活函数 Activation Function  1. 前馈神经网络这里用depth只有1的灰度图来举例。 想要完成的任务是：在宽长为4x4的图片中识别是否有下图所示的“横折”。 图中，黄色圆点表示值为0的像素，深色圆点表示值为1的像素。 我">
<meta property="og:locale" content="zh-Hans">
<meta property="og:image" content="http://godshen.github.io/2018/05/14/cs231n-study-note-2/ffnn1.jpg">
<meta property="og:image" content="http://godshen.github.io/2018/05/14/cs231n-study-note-2/ffnn2.jpg">
<meta property="og:image" content="http://godshen.github.io/2018/05/14/cs231n-study-note-2/ffnn3.jpg">
<meta property="og:image" content="http://godshen.github.io/2018/05/14/cs231n-study-note-2/cnn1.jpg">
<meta property="og:image" content="http://godshen.github.io/2018/05/14/cs231n-study-note-2/spaceSharing.gif">
<meta property="og:image" content="http://godshen.github.io/2018/05/14/cs231n-study-note-2/output1.jpg">
<meta property="og:image" content="http://godshen.github.io/2018/05/14/cs231n-study-note-2/output2.gif">
<meta property="og:image" content="http://godshen.github.io/2018/05/14/cs231n-study-note-2/depth1.jpg">
<meta property="og:image" content="http://godshen.github.io/2018/05/14/cs231n-study-note-2/depth2.jpg">
<meta property="og:image" content="http://godshen.github.io/2018/05/14/cs231n-study-note-2/zero1.jpg">
<meta property="og:image" content="http://godshen.github.io/2018/05/14/cs231n-study-note-2/figGet.jpg">
<meta property="og:image" content="http://godshen.github.io/2018/05/14/cs231n-study-note-2/figGet2.jpg">
<meta property="og:image" content="http://godshen.github.io/2018/05/14/cs231n-study-note-2/figGet3.jpg">
<meta property="og:image" content="http://godshen.github.io/2018/05/14/cs231n-study-note-2/mulFil11.jpg">
<meta property="og:image" content="http://godshen.github.io/2018/05/14/cs231n-study-note-2/mulFil12.jpg">
<meta property="og:image" content="http://godshen.github.io/2018/05/14/cs231n-study-note-2/mulFil2.gif">
<meta property="og:image" content="http://godshen.github.io/2018/05/14/cs231n-study-note-2/mulFil3.jpg">
<meta property="og:image" content="http://godshen.github.io/2018/05/14/cs231n-study-note-2/noneLine.jpg">
<meta property="og:image" content="http://godshen.github.io/2018/05/14/cs231n-study-note-2/squre.jpg">
<meta property="og:image" content="http://godshen.github.io/2018/05/14/cs231n-study-note-2/matrixExe.jpg">
<meta property="og:image" content="http://godshen.github.io/2018/05/14/cs231n-study-note-2/max1.jpg">
<meta property="og:image" content="http://godshen.github.io/2018/05/14/cs231n-study-note-2/max2.jpg">
<meta property="og:image" content="http://godshen.github.io/2018/05/14/cs231n-study-note-2/max3.jpg">
<meta property="og:image" content="http://godshen.github.io/2018/05/14/cs231n-study-note-2/all1.jpg">
<meta property="og:image" content="http://godshen.github.io/2018/05/14/cs231n-study-note-2/all2.jpg">
<meta property="og:image" content="http://godshen.github.io/2018/05/14/cs231n-study-note-2/actFun1.png">
<meta property="og:image" content="http://godshen.github.io/2018/05/14/cs231n-study-note-2/actFun2.png">
<meta property="og:updated_time" content="2019-04-05T07:33:47.764Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="cs231n study note 2">
<meta name="twitter:description" content="一. 学习内容 前馈神经网络 Feedforward Neural Network 卷积神经网络 Convolutional Neural Network 激活函数 Activation Function  1. 前馈神经网络这里用depth只有1的灰度图来举例。 想要完成的任务是：在宽长为4x4的图片中识别是否有下图所示的“横折”。 图中，黄色圆点表示值为0的像素，深色圆点表示值为1的像素。 我">
<meta name="twitter:image" content="http://godshen.github.io/2018/05/14/cs231n-study-note-2/ffnn1.jpg">





  
  
  <link rel="canonical" href="http://godshen.github.io/2018/05/14/cs231n-study-note-2/"/>



<script id="page.configurations">
  CONFIG.page = {
    sidebar: "",
  };
</script>

  <title>cs231n study note 2 | 沈中皓同学不好学</title>
  






  <script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?2c2185ce0cd226d402b516d6007f9577";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
  </script>







  <noscript>
  <style>
  .use-motion .motion-element,
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-title { opacity: initial; }

  .use-motion .logo,
  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript><!-- hexo-inject:begin --><!-- hexo-inject:end -->

</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">沈中皓同学不好学</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
    
      
        <p class="site-subtitle">stay hungry stay foolish</p>
      
    
    
  </div>

  <div class="site-nav-toggle">
    <button aria-label="Navigationsleiste an/ausschalten">
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>



<nav class="site-nav">
  
    <ul id="menu" class="menu">
      
        
        
        
          
          <li class="menu-item menu-item-home">

    
    
    
      
    

    

    <a href="/" rel="section"><i class="menu-item-icon fa fa-fw fa-home"></i> <br/>Startseite</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-about">

    
    
    
      
    

    

    <a href="/about/" rel="section"><i class="menu-item-icon fa fa-fw fa-user"></i> <br/>Über</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-tags">

    
    
    
      
    

    

    <a href="/tags/" rel="section"><i class="menu-item-icon fa fa-fw fa-tags"></i> <br/>Schlagwörter</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-categories">

    
    
    
      
    

    

    <a href="/categories/" rel="section"><i class="menu-item-icon fa fa-fw fa-th"></i> <br/>Kategorien</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-archives">

    
    
    
      
    

    

    <a href="/archives/" rel="section"><i class="menu-item-icon fa fa-fw fa-archive"></i> <br/>Archiv</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-schedule">

    
    
    
      
    

    

    <a href="/schedule/" rel="section"><i class="menu-item-icon fa fa-fw fa-calendar"></i> <br/>Zeitplan</a>

  </li>

      
      
    </ul>
  

  
    

  

  
</nav>



  



</div>
    </header>

    
  
  

  

  <a href="https://github.com/godshen" class="github-corner" title="Follow me on GitHub" aria-label="Follow me on GitHub" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a>



    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://godshen.github.io/2018/05/14/cs231n-study-note-2/"/>

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="godshen"/>
      <meta itemprop="description" content="Dangge Chihuo Zuoge Shabi"/>
      <meta itemprop="image" content="/images/lyh.jpg"/>
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="沈中皓同学不好学"/>
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">cs231n study note 2

              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Veröffentlicht am</span>
              

              
                
              

              <time title="Erstellt: 2018-05-14 21:08:10" itemprop="dateCreated datePublished" datetime="2018-05-14T21:08:10+08:00">2018-05-14</time>
            

            
              

              
                
                <span class="post-meta-divider">|</span>
                

                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Bearbeitet am</span>
                
                <time title="Geändert am: 2019-04-05 15:33:47" itemprop="dateModified" datetime="2019-04-05T15:33:47+08:00">2019-04-05</time>
              
            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">in</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/学习笔记/" itemprop="url" rel="index"><span itemprop="name">学习笔记</span></a></span>

                
                
              
            </span>
          

          
            
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <h1 id="一-学习内容"><a href="#一-学习内容" class="headerlink" title="一. 学习内容"></a>一. 学习内容</h1><ol>
<li>前馈神经网络 Feedforward Neural Network</li>
<li>卷积神经网络 Convolutional Neural Network</li>
<li>激活函数 Activation Function</li>
</ol>
<h2 id="1-前馈神经网络"><a href="#1-前馈神经网络" class="headerlink" title="1. 前馈神经网络"></a>1. 前馈神经网络</h2><p>这里用depth只有1的灰度图来举例。 想要完成的任务是：在宽长为4x4的图片中识别是否有下图所示的“横折”。 图中，黄色圆点表示值为0的像素，深色圆点表示值为1的像素。 我们知道不管这个横折在图片中的什么位置，都会被认为是相同的横折。<br><img src="/2018/05/14/cs231n-study-note-2/ffnn1.jpg" alt=""><br>若训练前馈神经网络来完成该任务，那么表达图像的三维张量将会被摊平成一个向量，作为网络的输入，即(width, height, depth)为(4, 4, 1)的图片会被展成维度为16的向量作为网络的输入层。再经过几层不同节点个数的隐藏层，最终输出两个节点，分别表示“有横折的概率”和“没有横折的概率”，如下图所示。<br><img src="/2018/05/14/cs231n-study-note-2/ffnn2.jpg" alt=""><br>下面我们用数字（16进制）对图片中的每一个像素点（pixel）进行编号。 当使用右侧那种物体位于中间的训练数据来训练网络时，网络就只会对编号为5,6,9,a的节点的权重进行调节。 若让该网络识别位于右下角的“横折”时，则无法识别。<br><img src="/2018/05/14/cs231n-study-note-2/ffnn3.jpg" alt=""><br>解决办法是用大量物体位于不同位置的数据训练，同时增加网络的隐藏层个数从而扩大网络学习这些变体的能力。</p>
<p>然而这样做十分不效率，因为我们知道在左侧的“横折”也好，还是在右侧的“横折”也罢，大家都是“横折”。 为什么相同的东西在位置变了之后要重新学习？有没有什么方法可以将中间所学到的规律也运用在其他的位置？ 换句话说，也就是<strong>让不同位置用相同的权重</strong>。</p>
<h2 id="2-卷积神经网络"><a href="#2-卷积神经网络" class="headerlink" title="2. 卷积神经网络"></a>2. 卷积神经网络</h2><p>卷积神经网络就是让权重在不同位置共享的神经网络。</p>
<h3 id="局部连接"><a href="#局部连接" class="headerlink" title="局部连接"></a>局部连接</h3><p>在卷积神经网络中，我们先选择一个局部区域，用这个局部区域去扫描整张图片。 局部区域所圈起来的所有节点会被连接到下一层的一个节点上。</p>
<p>为了更好的和前馈神经网络做比较，我将这些以矩阵排列的节点展成了向量。 下图展示了被红色方框所圈中编号为0,1,4,5的节点是如何通过$w_1,w_2,w_3,w_4$连接到下一层的节点0上的。<br><img src="/2018/05/14/cs231n-study-note-2/cnn1.jpg" alt=""><br>这个带有连接强弱的红色方框就叫做 <strong>filter</strong> 或 <strong>kernel</strong> 或 <strong>feature detector</strong>。 而filter的范围叫做<strong>filter size</strong>，这里所展示的是2x2的filter size。</p>
<script type="math/tex; mode=display">
\begin{bmatrix}
    w_1 & w_2  \\
    w_3 & w_4  \\
\end{bmatrix}\tag{1}</script><p>第二层的节点0的数值就是局部区域的线性组合，即被圈中节点的数值乘以对应的权重后相加。 用$x$表示输入值，$y$表示输出值，用图中标注数字表示角标，则下面列出了两种计算编号为0的输出值$y_0$的表达式。</p>
<p>注：在局部区域的线性组合后，也会和前馈神经网络一样，加上一个偏移量$b_0$ 。</p>
<script type="math/tex; mode=display">
y_0 = x_0 * w_1 + x_1 * w_2 + x_4 * w_3 + x_5 * w_4 + b_0</script><script type="math/tex; mode=display">
y_0 = \begin{bmatrix} w_1 & w_2 & w_3 & w_4 \end{bmatrix} 
 \cdot 
\begin{bmatrix}
    x_0  \\
    x_1  \\
    x_4  \\
    x_5  \\
\end{bmatrix}
+ b_0
\tag{2}</script><h3 id="空间共享"><a href="#空间共享" class="headerlink" title="空间共享"></a>空间共享</h3><p>当filter扫到其他位置计算输出节点 $ y_i $ 时，$ w_1,w_2,w_3,w_4 $，包括 $ b_0 $ 是共用的。</p>
<p>下面这张动态图展示了当filter扫过不同区域时，节点的链接方式。 动态图的最后一帧则显示了所有连接。 可以注意到，每个输出节点并非像前馈神经网络中那样与全部的输入节点连接，而是部分连接。 这也就是为什么大家也叫前馈神经网络（feedforward neural network）为fully-connected neural network。 图中显示的是一步一步的移动filter来扫描全图，一次移动多少叫做stride。<br><img src="/2018/05/14/cs231n-study-note-2/spaceSharing.gif" alt=""></p>
<blockquote>
<p>空间共享也就是卷积神经网络所引入的先验知识。</p>
</blockquote>
<h3 id="输出表达"><a href="#输出表达" class="headerlink" title="输出表达"></a>输出表达</h3><p>如先前在图像表达中提到的，图片不用向量去表示是为了保留图片平面结构的信息。 同样的，卷积后的输出若用上图的排列方式则丢失了平面结构信息。 所以我们依然用矩阵的方式排列它们，就得到了下图所展示的连接。<br><img src="/2018/05/14/cs231n-study-note-2/output1.jpg" alt=""><br>这也就是你们在网上所看到的下面这张图。在看这张图的时候请结合上图的连接一起理解，即输入（绿色）的每九个节点连接到输出（粉红色）的一个节点上的。<br><img src="/2018/05/14/cs231n-study-note-2/output2.gif" alt=""></p>
<p>经过一个feature detector计算后得到的粉红色区域也叫做一个<strong>“Convolved Feature”</strong> 或 <strong>“Activation Map” </strong>或<strong> “Feature Map”</strong>。</p>
<h3 id="Depth维的处理"><a href="#Depth维的处理" class="headerlink" title="Depth维的处理"></a>Depth维的处理</h3><p>现在我们已经知道了depth维度只有1的灰度图是如何处理的。 但前文提过，图片的普遍表达方式是下图这样有3个channels的RGB颜色模型。 当depth为复数的时候，每个feature detector是如何卷积的？<br><img src="/2018/05/14/cs231n-study-note-2/depth1.jpg" alt=""></p>
<p>现象：2x2所表达的filter size中，一个2表示width维上的局部连接数，另一个2表示height维上的局部连接数，并却没有depth维上的局部连接数，是因为depth维上并非局部，而是全部连接的。</p>
<p>在2D卷积中，filter在张量的width维, height维上是局部连接，在depth维上是贯串全部channels的。</p>
<p>类比：想象在切蛋糕的时候，不管这个蛋糕有多少层，通常大家都会一刀切到底，但是在长和宽这两个维上是局部切割。</p>
<p>下面这张图展示了，在depth为复数时，filter是如何连接输入节点到输出节点的。 图中红、绿、蓝颜色的节点表示3个channels。 黄色节点表示一个feature detector卷积后得到的Feature Map。 其中被透明黑框圈中的12个节点会被连接到黄黑色的节点上。</p>
<ul>
<li>在输入depth为1时：被filter size为2x2所圈中的4个输入节点连接到1个输出节点上。</li>
<li>在输入depth为3时：被filter size为2x2，但是贯串3个channels后，所圈中的12个输入节点连接到1个输出节点上。</li>
<li>在输入depth为n时：2x2xn个输入节点连接到1个输出节点上。<br><img src="/2018/05/14/cs231n-study-note-2/depth2.jpg" alt=""></li>
</ul>
<p><strong>注意：</strong> 三个channels的权重并不共享。 即当深度变为3后，权重也跟着扩增到了三组，如式子(3)所示，不同channels用的是自己的权重。 式子中增加的角标r,g,b分别表示red channel, green channel, blue channel的权重。</p>
<script type="math/tex; mode=display">
\left[ \begin{matrix} w_{r1}&w_{r2}\\ w_{r3}&w_{r4}\\ \end{matrix} \right], \left[ \begin{matrix} w_{g1}&w_{g2}\\ w_{g3}&w_{g4}\\ \end{matrix} \right], \left[ \begin{matrix} w_{b1}&w_{b2}\\ w_{b3}&w_{b4}\\ \end{matrix} \right] (3)</script><p>计算例子：用 Xr0 表示red channel的编号为0的输入结点, Xg5表示green channel的编号为5的输入结点, Xb1表示blue channel. 如式子(4)所表达, 这时的一个输出结点实际上是12个输入结点的线性组合. </p>
<script type="math/tex; mode=display">
\begin{split} y_0 &= x_{r0}*w_{r1} + x_{r1}*w_{r2}+ x_{r4}*w_{r3}+ x_{r5}*w_{r4}+ x_{g0}*w_{g1} + x_{g1}*w_{g2}+ x_{g4}*w_{g3}+ x_{g5}*w_{g4}+ x_{b0}*w_{b1} + x_{b1}*w_{b2}+ x_{b4}*w_{b3}+ x_{b5}*w_{b4}+b_0\\y_0 &= \left[ \begin{matrix} w_{r1}&w_{r2}& w_{r3}&w_{r4} \end{matrix} \right] \cdot \left[ \begin{matrix} x_{r0}\\ x_{r1}\\ x_{r4}\\ x_{r5}\\ \end{matrix} \right] +\left[ \begin{matrix} w_{g1}&w_{g2}& w_{g3}&w_{g4} \end{matrix} \right] \cdot \left[ \begin{matrix} x_{g0}\\ x_{g1}\\ x_{g4}\\ x_{g5}\\ \end{matrix} \right]+\left[ \begin{matrix} w_{b1}&w_{b2}& w_{b3}&w_{b4} \end{matrix} \right] \cdot \left[ \begin{matrix} x_{b0}\\ x_{b1}\\ x_{b4}\\ x_{b5}\\ \end{matrix} \right]+b_0\end{split}(4)</script><blockquote>
<p>当filter扫到其他位置计算输出节点y_i时，那12个权重在不同位置是共用的，如下面的动态图所展示。 透明黑框圈中的12个节点会连接到被白色边框选中的黄色节点上。</p>
</blockquote>
<h3 id="Zero-padding"><a href="#Zero-padding" class="headerlink" title="Zero padding"></a>Zero padding</h3><p>4x4的图片被2x2的filter卷积后变成了3x3的图片，每次卷积后都会小一圈的话，经过若干层后岂不是变的越来越小？ Zero padding就可以在这时帮助控制Feature Map的输出尺寸，同时避免了边缘信息被一步步舍弃的问题。</p>
<p>例如：下面4x4的图片在边缘Zero padding一圈后，再用3x3的filter卷积后，得到的Feature Map尺寸依然是4x4不变。<br><img src="/2018/05/14/cs231n-study-note-2/zero1.jpg" alt=""><br>通常大家都想要在卷积时保持图片的原始尺寸。 选择3x3的filter和1的zero padding，或5x5的filter和2的zero padding可以保持图片的原始尺寸。 这也是为什么大家多选择3x3和5x5的filter的原因。 另一个原因是3x3的filter考虑到了像素与其距离为1以内的所有其他像素的关系，而5x5则是考虑像素与其距离为2以内的所有其他像素的关系。</p>
<p><strong>尺寸：</strong>Feature Map的尺寸等于(input_size + 2 * padding_size − filter_size)/stride+1。</p>
<p><strong>注意：</strong>上面的式子是计算width或height一维的。padding_size也表示的是单边补零的个数。例如(4+2-3)/1+1 = 4，保持原尺寸。</p>
<p>不用背这个式子。其中(input_size + 2 * padding_size)是经过Zero padding扩充后真正要卷积的尺寸。 减去 filter_size后表示可以滑动的范围。 再除以可以一次滑动（stride）多少后得到滑动了多少次，也就意味着得到了多少个输出节点。 再加上第一个不需要滑动也存在的输出节点后就是最后的尺寸。</p>
<h3 id="形状、概念抓取"><a href="#形状、概念抓取" class="headerlink" title="形状、概念抓取"></a>形状、概念抓取</h3><p>知道了每个filter在做什么之后，我们再来思考这样的一个filter会抓取到什么样的信息。</p>
<p>我们知道不同的形状都可由细小的“零件”组合而成的。比如下图中，用2x2的范围所形成的16种形状可以组合成格式各样的“更大”形状。</p>
<p>卷积的每个filter可以探测特定的形状。又由于Feature Map保持了抓取后的空间结构。若将探测到细小图形的Feature Map作为新的输入再次卷积后，则可以由此探测到“更大”的形状概念。 比如下图的第一个“大”形状可由2,3,4,5基础形状拼成。第二个可由2,4,5,6组成。第三个可由6,1组成。<br><img src="/2018/05/14/cs231n-study-note-2/figGet.jpg" alt=""><br>除了基础形状之外，颜色、对比度等概念对画面的识别结果也有影响。卷积层也会根据需要去探测特定的概念。</p>
<p>可以从下面这张图中感受到不同数值的filters所卷积过后的Feature Map可以探测边缘，棱角，模糊，突出等概念。<br><img src="/2018/05/14/cs231n-study-note-2/figGet2.jpg" alt=""></p>
<p>如我们先前所提，图片被识别成什么不仅仅取决于图片本身，还取决于图片是如何被观察的。</p>
<p>而filter内的权重矩阵W是网络根据数据学习得到的，也就是说，我们让神经网络自己学习以什么样的方式去观察图片。</p>
<p>拿老妇与少女的那幅图片举例，当标签是少女时，卷积网络就会学习抓取可以成少女的形状、概念。 当标签是老妇时，卷积网络就会学习抓取可以成老妇的形状、概念。</p>
<p>下图展现了在人脸识别中经过层层的卷积后，所能够探测的形状、概念也变得越来越抽象和复杂。<br><img src="/2018/05/14/cs231n-study-note-2/figGet3.jpg" alt=""></p>
<blockquote>
<p>卷积神经网络会尽可能寻找最能解释训练数据的抓取方式。</p>
</blockquote>
<h3 id="多filters"><a href="#多filters" class="headerlink" title="多filters"></a>多filters</h3><p>每个filter可以抓取探测特定的形状的存在。 假如我们要探测下图的长方框形状时，可以用4个filters去探测4个基础“零件”。<br><img src="/2018/05/14/cs231n-study-note-2/mulFil11.jpg" alt=""><br><img src="/2018/05/14/cs231n-study-note-2/mulFil12.jpg" alt=""> </p>
<p>因此我们自然而然的会选择用多个不同的filters对同一个图片进行多次抓取。 如下图（动态图过大，如果显示不出，请看到该链接观看），同一个图片，经过两个（红色、绿色）不同的filters扫描过后可得到不同特点的Feature Maps。 每增加一个filter，就意味着你想让网络多抓取一个特征。<br><img src="/2018/05/14/cs231n-study-note-2/mulFil2.gif" alt=""></p>
<p>这样卷积层的输出也不再是depth为1的一个平面，而是和输入一样是depth为复数的长方体。</p>
<p>如下图所示，当我们增加一个filter（紫色表示）后，就又可以得到一个Feature Map。 将不同filters所卷积得到的Feature Maps按顺序堆叠后，就得到了一个卷积层的最终输出。<br><img src="/2018/05/14/cs231n-study-note-2/mulFil3.jpg" alt=""></p>
<blockquote>
<p>卷积层的输入是长方体，输出也是长方体。</p>
</blockquote>
<p>这样卷积后输出的长方体可以作为新的输入送入另一个卷积层中处理。</p>
<h3 id="加入非线性"><a href="#加入非线性" class="headerlink" title="加入非线性"></a>加入非线性</h3><p>和前馈神经网络一样，经过线性组合和偏移后，会加入非线性增强模型的拟合能力。</p>
<p>将卷积所得的Feature Map经过ReLU变换（elementwise）后所得到的output就如下图所展示。<br><img src="/2018/05/14/cs231n-study-note-2/noneLine.jpg" alt=""></p>
<h3 id="输出长方体"><a href="#输出长方体" class="headerlink" title="输出长方体"></a>输出长方体</h3><p>现在我们知道了一个卷积层的输出也是一个长方体。 那么这个输出长方体的(width, height, depth)由哪些因素决定和控制。</p>
<p>这里直接用CS231n的Summary：<br><img src="/2018/05/14/cs231n-study-note-2/squre.jpg" alt=""></p>
<p>计算例子：参见CS231n的Convolution Demo部分的演示。</p>
<h3 id="矩阵乘法执行卷积"><a href="#矩阵乘法执行卷积" class="headerlink" title="矩阵乘法执行卷积"></a>矩阵乘法执行卷积</h3><p>如果按常规以扫描的方式一步步计算局部节点和filter的权重的点乘，则不能高效的利用GPU的并行能力。 所以更普遍的方法是用两个大矩阵的乘法来一次性囊括所有计算。</p>
<p>因为卷积层的每个输出节点都是由若干个输入节点的线性组合所计算。 因为输出的节点个数是$W_2 \times H_2\times D_2$，所以就有$W_2 \times H_2\times D_2$个线性组合。</p>
<p>读过我写的线性代数教程的读者请回忆，矩阵乘矩阵的意义可以理解为批量的线性组合按顺序排列。 其中一个矩阵所表示的信息是多组权重，另一个矩阵所表示的信息是需要进行组合的向量。 大家习惯性的把组成成分放在矩阵乘法的右边，而把权重放在矩阵乘法的左边。 所以这个大型矩阵乘法可以用 </p>
<script type="math/tex; mode=display">
W_{row}\cdot X_{col}</script><p>表示，其中二者都是矩阵。<br><img src="/2018/05/14/cs231n-study-note-2/matrixExe.jpg" alt=""></p>
<p>卷积的每个输出是由局部的输入节点和对应的filter权重展成向量后所计算的，如式子(2)。 那么W<em>{row}中的每一行则是每个filter的权重，有F\cdot F \cdot D_1个； 而X</em>{col}的每一列是所有需要进行组合的节点（上面的动态图中被黑色透明框圈中的节点），也有F\cdot F \cdot D<em>1个。 X</em>{col}的列的个数则表示每个filter要滑动多少次才可以把整个图片扫描完，有W<em>2\cdot H_2次。 因为我们有多个filters，W</em>{row}的行的个数则是filter的个数K。</p>
<p>最后我们得到：</p>
<script type="math/tex; mode=display">
W_{row} \in R^{K \times F\cdot F \cdot D_1}
\\
X_{col} \in R^{F\cdot F \cdot D_1 \times W_2\cdot H_2}
\\
W_{row}\cdot X_{col} \in R^{K \times W_2\cdot H_2}</script><p>当然矩阵乘法后需要将</p>
<script type="math/tex; mode=display">
W_{row}\cdot X_{col}</script><p>整理成形状为</p>
<script type="math/tex; mode=display">
W_2 \times H_2\times D_2</script><p>的三维张量以供后续处理（如再送入另一个卷积层）。 </p>
<script type="math/tex; mode=display">
X_{col}</script><p>则也需要逐步的局部滑动图片，最后堆叠构成用于计算矩阵乘法的形式。</p>
<h3 id="Max-pooling"><a href="#Max-pooling" class="headerlink" title="Max pooling"></a>Max pooling</h3><p>在卷积后还会有一个pooling的操作，尽管有其他的比如average pooling等，这里只提max pooling。</p>
<p>max pooling的操作如下图所示：整个图片被不重叠的分割成若干个同样大小的小块（pooling size）。每个小块内只取最大的数字，再舍弃其他节点后，保持原有的平面结构得出output。<br><img src="/2018/05/14/cs231n-study-note-2/max1.jpg" alt=""></p>
<p>max pooling在不同的depth上是分开执行的，且不需要参数控制。 那么问题就max pooling有什么作用？部分信息被舍弃后难道没有影响吗？<br><img src="/2018/05/14/cs231n-study-note-2/max2.jpg" alt=""></p>
<p>Max pooling的主要功能是downsamping，却不会损坏识别结果。 这意味着卷积后的Feature Map中有对于识别物体不必要的冗余信息。 那么我们就反过来思考，这些“冗余”信息是如何产生的。</p>
<p>直觉上，我们为了探测到某个特定形状的存在，用一个filter对整个图片进行逐步扫描。但只有出现了该特定形状的区域所卷积获得的输出才是真正有用的，用该filter卷积其他区域得出的数值就可能对该形状是否存在的判定影响较小。 比如下图中，我们还是考虑探测“横折”这个形状。 卷积后得到3x3的Feature Map中，真正有用的就是数字为3的那个节点，其余数值对于这个任务而言都是无关的。 所以用3x3的Max pooling后，并没有对“横折”的探测产生影响。 试想在这里例子中如果不使用Max pooling，而让网络自己去学习。 网络也会去学习与Max pooling近似效果的权重。因为是近似效果，增加了更多的parameters的代价，却还不如直接进行Max pooling。<br><img src="/2018/05/14/cs231n-study-note-2/max3.jpg" alt=""></p>
<p>Max pooling还有类似“选择句”的功能。假如有两个节点，其中第一个节点会在某些输入情况下最大，那么网络就只在这个节点上流通信息；而另一些输入又会让第二个节点的值最大，那么网络就转而走这个节点的分支。</p>
<p>但是Max pooling也有不好的地方。因为并非所有的抓取都像上图的例子。有些周边信息对某个概念是否存在的判定也有影响。 并且Max pooling是对所有的Feature Maps进行等价的操作。就好比用相同网孔的渔网打鱼，一定会有漏网之鱼。</p>
<h3 id="全连接层"><a href="#全连接层" class="headerlink" title="全连接层"></a>全连接层</h3><p>当抓取到足以用来识别图片的特征后，接下来的就是如何进行分类。 全连接层（也叫前馈层）就可以用来将最后的输出映射到线性可分的空间。 通常卷积网络的最后会将末端得到的长方体平摊(flatten)成一个长长的向量，并送入全连接层配合输出层进行分类。</p>
<p>卷积神经网络大致就是covolutional layer, pooling layer, ReLu layer, fully-connected layer的组合，例如下图所示的结构。<br><img src="/2018/05/14/cs231n-study-note-2/all1.jpg" alt=""></p>
<p>这里也体现了深层神经网络或deep learning之所以称deep的一个原因：模型将特征抓取层和分类层合在了一起。 负责特征抓取的卷积层主要是用来学习“如何观察”。</p>
<p>下图简述了机器学习的发展，从最初的人工定义特征再放入分类器的方法，到让机器自己学习特征，再到如今尽量减少人为干涉的deep learning。<br><img src="/2018/05/14/cs231n-study-note-2/all2.jpg" alt=""></p>
<h3 id="结构发展"><a href="#结构发展" class="headerlink" title="结构发展"></a>结构发展</h3><p>以上介绍了卷积神经网络的基本概念。 以下是几个比较有名的卷积神经网络结构</p>
<ul>
<li>LeNet：第一个成功的卷积神经网络应用</li>
<li>AlexNet：类似LeNet，但更深更大。使用了层叠的卷积层来抓取特征（通常是一个卷积层马上一个max pooling层）</li>
<li>ZF Net：增加了中间卷积层的尺寸，让第一层的stride和filter size更小。</li>
<li>GoogLeNet：减少parameters数量，最后一层用max pooling层代替了全连接层，更重要的是Inception-v4模块的使用。</li>
<li>VGGNet：只使用3x3 卷积层和2x2 pooling层从头到尾堆叠。</li>
<li>ResNet：引入了跨层连接和batch normalization。</li>
<li>DenseNet：将跨层连接从头进行到尾</li>
</ul>
<p>总结一下：这些结构的发展趋势有：</p>
<ul>
<li>使用small filter size的卷积层和pooling</li>
<li>去掉parameters过多的全连接层</li>
<li>Inception（稍后会对其中的细节进行说明）</li>
<li>跳层连接</li>
</ul>
<h2 id="3-激活函数"><a href="#3-激活函数" class="headerlink" title="3. 激活函数"></a>3. 激活函数</h2><h3 id="激活函数通常有如下一些性质："><a href="#激活函数通常有如下一些性质：" class="headerlink" title="激活函数通常有如下一些性质："></a>激活函数通常有如下一些性质：</h3><p><strong>非线性：</strong> 当激活函数是线性的时候，一个两层的神经网络就可以逼近基本上所有的函数了。但是，如果激活函数是恒等激活函数的时候（即f(x)=x），就不满足这个性质了，而且如果MLP使用的是恒等激活函数，那么其实整个网络跟单层神经网络是等价的。</p>
<p><strong>可微性：</strong> 当优化方法是基于梯度的时候，这个性质是必须的。</p>
<p><strong>单调性： </strong>当激活函数是单调的时候，单层网络能够保证是凸函数。</p>
<p><strong>f(x)≈x：</strong> 当激活函数满足这个性质的时候，如果参数的初始化是random的很小的值，那么神经网络的训练将会很高效；如果不满足这个性质，那么就需要很用心的去设置初始值。</p>
<p><strong>输出值的范围：</strong> 当激活函数输出值是 有限 的时候，基于梯度的优化方法会更加 稳定，因为特征的表示受有限权值的影响更显著；当激活函数的输出是 无限 的时候，模型的训练会更加高效，不过在这种情况小，一般需要更小的learning rate.</p>
<h3 id="Sigmoid"><a href="#Sigmoid" class="headerlink" title="Sigmoid"></a>Sigmoid</h3><p><img src="/2018/05/14/cs231n-study-note-2/actFun1.png" alt=""></p>
<h3 id="ReLU"><a href="#ReLU" class="headerlink" title="ReLU"></a>ReLU</h3><p><img src="/2018/05/14/cs231n-study-note-2/actFun2.png" alt=""></p>
<h1 id="二-工作相关"><a href="#二-工作相关" class="headerlink" title="二. 工作相关"></a>二. 工作相关</h1><h3 id="遗传算法"><a href="#遗传算法" class="headerlink" title="遗传算法"></a>遗传算法</h3><ol>
<li>遗传算法与机器学习-不确定性优化</li>
<li>遗传算法原理简述</li>
<li>遗传算法解决机器视觉问题</li>
<li>遗传算法缺点与局限性</li>
</ol>

      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/cnn/" rel="tag"># cnn</a>
          
            <a href="/tags/activation-function/" rel="tag"># activation function</a>
          
        </div>
      

      
      
        <div class="post-widgets">
        

        

        
          
          <div class="social_share">
            
              <div>
                

<script src="//cdn.jsdelivr.net/npm/ilyabirman-likely@2/release/likely.js"></script>



<link rel="stylesheet" href="//cdn.jsdelivr.net/npm/ilyabirman-likely@2/release/likely.css">


  


<div class="likely">
	
 	 	<div class="twitter">Tweet</div>
	
 	 	<div class="facebook">Share</div>
	
 	 	<div class="linkedin">Link</div>
	
 	 	<div class="gplus">Plus</div>
	
 	 	<div class="vkontakte">Share</div>
	
 	 	<div class="odnoklassniki">Class</div>
	
 	 	<div class="telegram">Send</div>
	
 	 	<div class="whatsapp">Send</div>
	
 	 	<div class="pinterest">Pin</div>
	
</div>

              </div>
            
            
            
          </div>
        
        </div>
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2018/05/14/cs231n-study-note-1/" rel="next" title="cs231n study note 1">
                <i class="fa fa-chevron-left"></i> cs231n study note 1
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2019/04/05/BP练习作业/" rel="prev" title="BP homowork">
                BP homowork <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>


  </div>


          </div>
          

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            Inhaltsverzeichnis
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            Übersicht
          </li>
        </ul>
      

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image"
                src="/images/lyh.jpg"
                alt="godshen"/>
            
              <p class="site-author-name" itemprop="name">godshen</p>
              <div class="site-description motion-element" itemprop="description">Dangge Chihuo Zuoge Shabi</div>
          </div>

          
            <nav class="site-state motion-element">
              
                <div class="site-state-item site-state-posts">
                
                  <a href="/archives/">
                
                    <span class="site-state-item-count">8</span>
                    <span class="site-state-item-name">Artikel</span>
                  </a>
                </div>
              

              
                
                
                <div class="site-state-item site-state-categories">
                  
                    
                      <a href="/categories/">
                    
                  
                    
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">5</span>
                    <span class="site-state-item-name">Kategorien</span>
                  </a>
                </div>
              

              
                
                
                <div class="site-state-item site-state-tags">
                  
                    
                      <a href="/tags/">
                    
                  
                    
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">22</span>
                    <span class="site-state-item-name">schlagwörter</span>
                  </a>
                </div>
              
            </nav>
          

          

          

          

          

          
          

          
            
          
          

        </div>
      </div>

      
      <!--noindex-->
        <div class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
            
            
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#一-学习内容"><span class="nav-number">1.</span> <span class="nav-text">一. 学习内容</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#1-前馈神经网络"><span class="nav-number">1.1.</span> <span class="nav-text">1. 前馈神经网络</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-卷积神经网络"><span class="nav-number">1.2.</span> <span class="nav-text">2. 卷积神经网络</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#局部连接"><span class="nav-number">1.2.1.</span> <span class="nav-text">局部连接</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#空间共享"><span class="nav-number">1.2.2.</span> <span class="nav-text">空间共享</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#输出表达"><span class="nav-number">1.2.3.</span> <span class="nav-text">输出表达</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Depth维的处理"><span class="nav-number">1.2.4.</span> <span class="nav-text">Depth维的处理</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Zero-padding"><span class="nav-number">1.2.5.</span> <span class="nav-text">Zero padding</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#形状、概念抓取"><span class="nav-number">1.2.6.</span> <span class="nav-text">形状、概念抓取</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#多filters"><span class="nav-number">1.2.7.</span> <span class="nav-text">多filters</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#加入非线性"><span class="nav-number">1.2.8.</span> <span class="nav-text">加入非线性</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#输出长方体"><span class="nav-number">1.2.9.</span> <span class="nav-text">输出长方体</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#矩阵乘法执行卷积"><span class="nav-number">1.2.10.</span> <span class="nav-text">矩阵乘法执行卷积</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Max-pooling"><span class="nav-number">1.2.11.</span> <span class="nav-text">Max pooling</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#全连接层"><span class="nav-number">1.2.12.</span> <span class="nav-text">全连接层</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#结构发展"><span class="nav-number">1.2.13.</span> <span class="nav-text">结构发展</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-激活函数"><span class="nav-number">1.3.</span> <span class="nav-text">3. 激活函数</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#激活函数通常有如下一些性质："><span class="nav-number">1.3.1.</span> <span class="nav-text">激活函数通常有如下一些性质：</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Sigmoid"><span class="nav-number">1.3.2.</span> <span class="nav-text">Sigmoid</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#ReLU"><span class="nav-number">1.3.3.</span> <span class="nav-text">ReLU</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#二-工作相关"><span class="nav-number">2.</span> <span class="nav-text">二. 工作相关</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#遗传算法"><span class="nav-number">2.0.1.</span> <span class="nav-text">遗传算法</span></a></li></ol></li></ol></li></ol></div>
            

          </div>
        </div>
      <!--/noindex-->
      

      

    </div>
  </aside>
  


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love" id="animate">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">godshen</span>

  

  
</div>


  <div class="powered-by">Erstellt mit  <a href="https://hexo.io" class="theme-link" rel="noopener" target="_blank">Hexo</a> v3.3.9</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Design – <a href="https://theme-next.org" class="theme-link" rel="noopener" target="_blank">NexT.Muse</a> v7.1.0</div>




        








        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

    

    
  </div>

  

<script>
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>


























  
  <script src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>


  


  <script src="/js/utils.js?v=7.1.0"></script>

  <script src="/js/motion.js?v=7.1.0"></script>



  
  


  <script src="/js/schemes/muse.js?v=7.1.0"></script>



  
  <script src="/js/scrollspy.js?v=7.1.0"></script>
<script src="/js/post-details.js?v=7.1.0"></script>



  


  <script src="/js/next-boot.js?v=7.1.0"></script>


  

  

  

  


  


  




  

  

  

  

  

  
  <script>
    (function(){
      var bp = document.createElement('script');
      var curProtocol = window.location.protocol.split(':')[0];
      bp.src = (curProtocol === 'https') ? 'https://zz.bdstatic.com/linksubmit/push.js' : 'http://push.zhanzhang.baidu.com/push.js';
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(bp, s);
    })();
  </script><!-- hexo-inject:begin --><!-- hexo-inject:end -->


  

  

  

  

  

  

  

  

<!-- mathjax config similar to math.stackexchange -->

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true
    }
  });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      }
    });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for(i=0; i < all.length; i += 1) {
            all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>

<script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
</body>
</html>
